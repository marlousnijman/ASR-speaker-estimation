{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ec1573",
   "metadata": {},
   "source": [
    "# Number of Speaker Estimation Using CountNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0511332a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2e905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import soundfile as sf\n",
    "import webrtcvad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52195d38",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb0ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/dev-clean/LibriSpeech/\"\n",
    "dev_data_path = os.path.join(data_path, \"dev-clean/\")\n",
    "processed_data_path = os.path.join(data_path, \"dev_clean_processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2b3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b9c56",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6dcf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    filepaths = []\n",
    "    files = []\n",
    "\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".flac\"):\n",
    "                filepaths.append(os.path.join(dirpath, filename))\n",
    "                files.append(filename)\n",
    "\n",
    "    return list(zip(filepaths, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d40eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(audio, sample_rate, ms):\n",
    "    n = int(sample_rate * (ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "\n",
    "    frames = []\n",
    "    while offset + n < len(audio):\n",
    "        frames.append(audio[offset:offset + n])\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e15b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_frames(frame_ids, start_id=0):\n",
    "    start_frame_ids = []\n",
    "    start = start_id\n",
    "    for frame_id in frame_ids:\n",
    "        if frame_id == start:\n",
    "            start_frame_ids.append(frame_id)\n",
    "            start += 1\n",
    "    \n",
    "    return start_frame_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17daf3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_frames(frame_ids, end_id):\n",
    "    end_frame_ids = []\n",
    "    end = end_id\n",
    "    \n",
    "    frame_ids.reverse()\n",
    "    for frame_id in frame_ids:\n",
    "        if frame_id == end:\n",
    "            end_frame_ids.append(frame_id)\n",
    "            end -= 1\n",
    "    \n",
    "    return end_frame_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f72088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_audio(audio, sample_rate, s):\n",
    "    samples = sample_rate * s\n",
    "    start = 0\n",
    "    if len(audio) > samples:\n",
    "        start = random.choice(range(len(audio)-samples))\n",
    "\n",
    "    return audio[start:start+samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b4c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath, filename in get_files(dev_data_path):\n",
    "    audio, sample_rate = sf.read(filepath)\n",
    "    frames = get_frames(audio, sample_rate, 10)\n",
    "    vad = webrtcvad.Vad(0)\n",
    "\n",
    "    no_voice_frame_ids = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        if(vad.is_speech(frame, sample_rate) == False):\n",
    "            no_voice_frame_ids.append(i)\n",
    "\n",
    "    if len(no_voice_frame_ids) > 0:\n",
    "        start = max(get_start_frames(no_voice_frame_ids), default=0)\n",
    "        end = min(get_end_frames(no_voice_frame_ids, len(frames)-1), default=len(frames))\n",
    "        frames = frames[start:end]\n",
    "\n",
    "    new_audio = np.asarray([item for sublist in frames for item in sublist])\n",
    "    duration = len(new_audio) / sample_rate\n",
    "\n",
    "    if duration >= 10:\n",
    "        sel_new_audio = select_audio(new_audio, sample_rate, 10)\n",
    "        sf.write(os.path.join(processed_data_path, filename.replace(\".flac\", \".wav\")), sel_new_audio, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c761a",
   "metadata": {},
   "source": [
    "## Get Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9dbf774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_speakers(path, k):\n",
    "    all_speakers = os.listdir(path)\n",
    "    k_speakers = random.sample(all_speakers, k)\n",
    "    # Keep track of which were already used\n",
    "\n",
    "    return k_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a1ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = select_speakers(processed_data_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f5ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_audio = []\n",
    "for speaker in speakers:\n",
    "    audio, sample_rate = sf.read(os.path.join(processed_data_path,speaker))\n",
    "    all_audio.append(audio)\n",
    "\n",
    "test = np.sum(all_audio, axis=0)\n",
    "sf.write(\"test.wav\", test, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab700947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a certain value of k = {0, ..., 10}?\n",
    "# [x] Collect random samples of different speakers\n",
    "# [x] Remove begin and end silence\n",
    "# [x] Add individual samples \n",
    "# [] Peak normalized\n",
    "# [] Transformed to time-frequency matrix\n",
    "# \n",
    "# To compute ground-truth k:\n",
    "# Determine location where there is voice activity\n",
    "# Compute maximum number of concurrent speakers in sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084e171",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "asr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
